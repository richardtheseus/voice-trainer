<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Humming Note Identifier (Debug)</title>
  <style>
    body {
      display: flex;
      flex-direction: column;
      align-items: center;
      background: #f0f4f8;
      font-family: Arial, sans-serif;
      padding: 20px;
    }
    h1 {
      margin-bottom: 20px;
      text-align: center;
    }
    #toggle-button {
      padding: 10px 20px;
      font-size: 16px;
      border: none;
      border-radius: 6px;
      background: #3498db;
      color: white;
      cursor: pointer;
      margin-bottom: 20px;
    }
    #toggle-button.listening {
      background: #e74c3c;
    }
    #output {
      font-size: 24px;
      background: #fff;
      padding: 15px 20px;
      border-radius: 6px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
      min-width: 300px;
      text-align: center;
    }
    #note-name {
      font-weight: bold;
      margin-bottom: 5px;
    }
    #frequency {
      color: #555;
    }
    #error-msg {
      margin-top: 15px;
      color: #c0392b;
      font-size: 16px;
      text-align: center;
    }
  </style>
</head>
<body>
  <h1>Humming Note Identifier (Debug)</h1>
  <button id="toggle-button">Start Listening</button>
  <div id="output">
    <div id="note-name">â€”</div>
    <div id="frequency">â€”</div>
  </div>
  <div id="error-msg"></div>

  <script>
    // Precompute notes from MIDI 36 (C2) to 84 (C6)
    const NOTE_NAMES = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
    const A4_MIDI = 69;
    const A4_FREQ = 440.0;
    const allNotes = [];
    for (let m = 36; m <= 84; m++) {
      const freq = A4_FREQ * Math.pow(2, (m - A4_MIDI) / 12);
      const octave = Math.floor(m / 12) - 1;
      const name = NOTE_NAMES[m % 12] + octave;
      allNotes.push({ midi: m, name: name, freq: freq });
    }

    function findClosestNote(freq) {
      let best = null;
      let bestDist = Infinity;
      for (let note of allNotes) {
        const cents = Math.abs(1200 * Math.log2(freq / note.freq));
        if (cents < bestDist) {
          bestDist = cents;
          best = note;
        }
      }
      return best;
    }

    function autoCorrelate(buffer, sampleRate) {
      let SIZE = buffer.length;
      let rms = 0;
      for (let i = 0; i < SIZE; i++) {
        rms += buffer[i] * buffer[i];
      }
      rms = Math.sqrt(rms / SIZE);
      if (rms < 0.01) return -1;  // too quiet

      let r1 = 0, r2 = SIZE - 1, threshold = 0.2;
      for (let i = 0; i < SIZE / 2; i++) {
        if (Math.abs(buffer[i]) < threshold) {
          r1 = i;
          break;
        }
      }
      for (let i = 1; i < SIZE / 2; i++) {
        if (Math.abs(buffer[SIZE - i]) < threshold) {
          r2 = SIZE - i;
          break;
        }
      }
      const trimmed = buffer.slice(r1, r2);
      SIZE = trimmed.length;
      const c = new Array(SIZE).fill(0);
      for (let i = 0; i < SIZE; i++) {
        for (let j = 0; j < SIZE - i; j++) {
          c[i] += trimmed[j] * trimmed[j + i];
        }
      }
      let d = 0;
      while (c[d] > c[d + 1]) d++;
      let maxval = -1, maxpos = -1;
      for (let i = d; i < SIZE; i++) {
        if (c[i] > maxval) {
          maxval = c[i];
          maxpos = i;
        }
      }
      let T0 = maxpos;
      const x1 = c[T0 - 1], x2 = c[T0], x3 = c[T0 + 1];
      const a = (x1 + x3 - 2 * x2) / 2;
      const b = (x3 - x1) / 2;
      if (a) T0 = T0 - b / (2 * a);
      return sampleRate / T0;
    }

    let audioContext = null;
    let analyserNode = null;
    let mediaStreamSource = null;
    let listening = false;
    const toggleBtn = document.getElementById('toggle-button');
    const noteNameDiv = document.getElementById('note-name');
    const freqDiv = document.getElementById('frequency');
    const errorMsgDiv = document.getElementById('error-msg');

    // First: check microphone permission via Permissions API (if available)
    async function checkMicrophonePermission() {
      if (!navigator.permissions) {
        // Permissions API not supported â†’ skip check
        return 'prompt';
      }
      try {
        const status = await navigator.permissions.query({ name: 'microphone' });
        return status.state; // 'granted', 'denied', or 'prompt'
      } catch (e) {
        console.warn('Permissions API error:', e);
        return 'prompt';
      }
    }

    async function startListening() {
      errorMsgDiv.textContent = '';
      const perm = await checkMicrophonePermission();
      if (perm === 'denied') {
        errorMsgDiv.textContent = 'âš ï¸ Microphone permission is already denied. Please enable microphone access in your browser settings.';
        return;
      }
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        alert('ðŸ”´ getUserMedia is not supported by your browser');
        return;
      }

      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
      } catch (e) {
        console.error('AudioContext creation failed:', e);
        alert('ERROR: Could not create AudioContext. Your browser may be blocking audio.');
        return;
      }

      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStreamSource = audioContext.createMediaStreamSource(stream);
        analyserNode = audioContext.createAnalyser();
        analyserNode.fftSize = 2048;
        analyserNode.smoothingTimeConstant = 0.8;
        mediaStreamSource.connect(analyserNode);

        listening = true;
        toggleBtn.textContent = 'Stop Listening';
        toggleBtn.classList.add('listening');
        noteNameDiv.textContent = 'â€¦';
        freqDiv.textContent = 'â€¦';
        errorMsgDiv.textContent = '';

        listenLoop();
      } catch (err) {
        console.error('getUserMedia error:', err);
        if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
          alert('ðŸ”´ Microphone access denied. Please allow microphone access in your browser settings.');
        } else {
          alert('ðŸ”´ getUserMedia error: ' + err.message);
        }
      }
    }

    function stopListening() {
      listening = false;
      if (mediaStreamSource && mediaStreamSource.mediaStream) {
        mediaStreamSource.mediaStream.getTracks().forEach(t => t.stop());
      }
      if (audioContext) {
        audioContext.close();
      }
      audioContext = null;
      analyserNode = null;
      mediaStreamSource = null;
      toggleBtn.textContent = 'Start Listening';
      toggleBtn.classList.remove('listening');
      noteNameDiv.textContent = 'â€”';
      freqDiv.textContent = 'â€”';
    }

    function listenLoop() {
      if (!listening || !analyserNode) return;
      const buffer = new Float32Array(analyserNode.fftSize);

      function update() {
        if (!listening) return;
        analyserNode.getFloatTimeDomainData(buffer);
        const pitch = autoCorrelate(buffer, audioContext.sampleRate);
        if (pitch !== -1) {
          const closest = findClosestNote(pitch);
          if (closest) {
            noteNameDiv.textContent = closest.name;
            freqDiv.textContent = pitch.toFixed(2) + ' Hz';
          } else {
            noteNameDiv.textContent = 'â€”';
            freqDiv.textContent = pitch.toFixed(2) + ' Hz';
          }
        }
        requestAnimationFrame(update);
      }
      requestAnimationFrame(update);
    }

    toggleBtn.addEventListener('click', () => {
      if (!listening) {
        startListening();
      } else {
        stopListening();
      }
    });
  </script>
</body>
</html>
